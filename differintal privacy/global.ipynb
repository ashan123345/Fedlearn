{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load original dataset\n",
    "df = pd.read_csv(\"framinghamdataset.csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=['TenYearCHD'])\n",
    "y = df['TenYearCHD']\n",
    "\n",
    "# Scaling data (must be consistent for server and clients)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset: 1/3 for global testing, 2/3 for client training\n",
    "X_clients, X_global, y_clients, y_global = train_test_split(\n",
    "    X_scaled, y, test_size=1/3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Apply SMOTE only on the client training set (2/3 portion)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_clients_res, y_clients_res = smote.fit_resample(X_clients, y_clients)\n",
    "\n",
    "# Save data for Global server evaluation\n",
    "np.save('X_global.npy', X_global)\n",
    "np.save('y_global.npy', y_global)\n",
    "\n",
    "# Save data for Client-side simulations\n",
    "np.save('X_clients.npy', X_clients_res)\n",
    "np.save('y_clients.npy', y_clients_res)\n",
    "\n",
    "print(\"‚úÖ Data successfully divided:\")\n",
    "print(f\"Global evaluation data: {X_global.shape}\")\n",
    "print(f\"Client training data (after SMOTE): {X_clients_res.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_global = np.load('X_global.npy')\n",
    "y_global = np.load('y_global.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'X_clients.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# ‚úÖ Load Data (Only Needed for Input Size)\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m X_clients \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_clients.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m input_size \u001b[38;5;241m=\u001b[39m X_clients\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# ‚úÖ Initialize the Global Model\u001b[39;00m\n",
      "File \u001b[1;32md:\\Rreserch work\\fedenvioremnt\\.venv\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X_clients.npy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple\n",
    "from flwr.common import Parameters, FitRes, EvaluateRes, ndarrays_to_parameters\n",
    "\n",
    "# ‚úÖ Define the Global Model\n",
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# ‚úÖ Load Data (Only Needed for Input Size)\n",
    "X_clients = np.load('X_clients.npy')\n",
    "input_size = X_clients.shape[1]\n",
    "\n",
    "# ‚úÖ Initialize the Global Model\n",
    "global_model = GlobalModel(input_size)\n",
    "global_parameters = [val.cpu().detach().numpy() for val in global_model.parameters()]\n",
    "\n",
    "# ‚úÖ Custom FedProx Strategy with Accuracy Calculation\n",
    "class CustomFedProx(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, initial_parameters):\n",
    "        super().__init__()\n",
    "        self.initial_parameters = initial_parameters\n",
    "\n",
    "    def initialize_parameters(self, client_manager):\n",
    "        return ndarrays_to_parameters(self.initial_parameters)\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "    self,\n",
    "    rnd: int,\n",
    "    results: List[Tuple[fl.common.Parameters, EvaluateRes]],\n",
    "    failures: List[BaseException],\n",
    "    ) -> Tuple[float, dict]:\n",
    "        \"\"\"Aggregate evaluation results and print global accuracy.\"\"\"\n",
    "        \n",
    "        if not results:\n",
    "            print(f\"‚ö†Ô∏è Round {rnd}: No evaluation results received!\")\n",
    "            return 0.0, {\"accuracy\": 0.0}  # ‚úÖ Return a valid tuple\n",
    "\n",
    "        accuracies = [r.metrics[\"accuracy\"] for _, r in results]\n",
    "        global_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "        print(f\"üìä Round {rnd}: Global Model Accuracy: {global_accuracy:.4f}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# ‚úÖ Initialize Strategy with Global Model Parameters\n",
    "strategy = CustomFedProx(initial_parameters=global_parameters)\n",
    "\n",
    "# ‚úÖ Start Federated Learning Server (Runs for 30 Rounds)\n",
    "fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8080\",\n",
    "    strategy=strategy,\n",
    "    config=fl.server.ServerConfig(num_rounds=10)  # Adjust the number of rounds\n",
    ")\n",
    "\n",
    "# ‚úÖ Evaluate the Final Global Model\n",
    "global_model.eval()\n",
    "print(\"üéØ Final Global Model Evaluation Completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
      "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
      "\n",
      "\t\t$ flower-superlink --insecure\n",
      "\n",
      "\tTo view usage and all available options, run:\n",
      "\n",
      "\t\t$ flower-superlink --help\n",
      "\n",
      "\tUsing `start_server()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      Flower ECE: gRPC server running (10 rounds), SSL is disabled\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 1: Global Model Accuracy: 0.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 2: Global Model Accuracy: 0.8482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 3: Global Model Accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 4: Global Model Accuracy: 0.8517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 5: Global Model Accuracy: 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 6: Global Model Accuracy: 0.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 7: Global Model Accuracy: 0.8467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 8: Global Model Accuracy: 0.8565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 9: Global Model Accuracy: 0.8510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 366.59s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.163388007320862),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.848166489051909),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.8462059167810896),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.8517030308504188),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.8538673694478915),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.8435189486241279),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.8467222551270368),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.8564715543552247),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.8509887255248463),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.8599617562827389)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 10: Global Model Accuracy: 0.8600\n",
      "üéØ Final Global Model Evaluation Completed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple\n",
    "from flwr.common import Parameters, EvaluateRes, ndarrays_to_parameters\n",
    "\n",
    "\n",
    "# ‚úÖ Define the Global Model\n",
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# ‚úÖ Load Data (Only Needed for Input Size)\n",
    "X_clients = np.load('X_clients.npy')\n",
    "input_size = X_clients.shape[1]\n",
    "\n",
    "# ‚úÖ Initialize the Global Model\n",
    "global_model = GlobalModel(input_size)\n",
    "global_parameters = [val.cpu().detach().numpy() for val in global_model.parameters()]\n",
    "\n",
    "# ‚úÖ Custom FedProx Strategy with Accuracy Calculation\n",
    "class CustomFedProx(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, initial_parameters):\n",
    "        super().__init__()\n",
    "        self.initial_parameters = initial_parameters\n",
    "\n",
    "    def initialize_parameters(self, client_manager):\n",
    "        return ndarrays_to_parameters(self.initial_parameters)\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[Parameters, EvaluateRes]],\n",
    "        failures: List[BaseException],\n",
    "    ) -> Tuple[float, dict]:\n",
    "        \"\"\"Aggregate evaluation results and print global accuracy.\"\"\"\n",
    "        \n",
    "        if not results:\n",
    "            print(f\"‚ö†Ô∏è Round {rnd}: No evaluation results received!\")\n",
    "            return 0.0, {\"accuracy\": 0.0}  # ‚úÖ Return a valid tuple (loss, metrics)\n",
    "\n",
    "        accuracies = [r.metrics[\"accuracy\"] for _, r in results]\n",
    "        global_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "        print(f\"üìä Round {rnd}: Global Model Accuracy: {global_accuracy:.4f}\")\n",
    "\n",
    "        return 0.0, {\"accuracy\": global_accuracy}  # ‚úÖ Return (loss, metrics)\n",
    "\n",
    "# ‚úÖ Initialize Strategy with Global Model Parameters\n",
    "strategy = CustomFedProx(initial_parameters=global_parameters)\n",
    "\n",
    "# ‚úÖ Start Federated Learning Server (Runs for 30 Rounds)\n",
    "fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8080\",\n",
    "    strategy=strategy,\n",
    "    config=fl.server.ServerConfig(num_rounds=10)  # Adjust the number of rounds\n",
    ")\n",
    "\n",
    "# ‚úÖ Evaluate the Final Global Model\n",
    "global_model.eval()\n",
    "print(\"üéØ Final Global Model Evaluation Completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 3.2 secure agreagtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
      "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
      "\n",
      "\t\t$ flower-superlink --insecure\n",
      "\n",
      "\tTo view usage and all available options, run:\n",
      "\n",
      "\t\t$ flower-superlink --help\n",
      "\n",
      "\tUsing `start_server()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      Flower ECE: gRPC server running (10 rounds), SSL is disabled\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 1: Global Model Accuracy: 0.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 2: Global Model Accuracy: 0.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 3: Global Model Accuracy: 0.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Round 4: Global Model Accuracy: 0.6696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 1 failures\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from flwr.common import Parameters, EvaluateRes, ndarrays_to_parameters\n",
    "\n",
    "# ‚úÖ Define the Global Model\n",
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# ‚úÖ Load Data (For Input Size)\n",
    "X_clients = np.load('X_clients.npy')\n",
    "input_size = X_clients.shape[1]\n",
    "\n",
    "# ‚úÖ Initialize the Global Model\n",
    "global_model = GlobalModel(input_size)\n",
    "global_parameters = [val.cpu().detach().numpy() for val in global_model.parameters()]\n",
    "\n",
    "# ‚úÖ Custom FedProx Strategy with Accuracy Calculation & Secure Aggregation\n",
    "# Corrected CustomFedProx strategy\n",
    "class CustomFedProx(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, initial_parameters):\n",
    "        super().__init__(\n",
    "            fraction_fit=1.0,\n",
    "            fraction_evaluate=1.0,\n",
    "            min_fit_clients=2,\n",
    "            min_evaluate_clients=2,\n",
    "            min_available_clients=2,\n",
    "            # use_secure_aggregation REMOVED HERE\n",
    "        )\n",
    "        self.initial_parameters = initial_parameters\n",
    "\n",
    "    def initialize_parameters(self, client_manager):\n",
    "        return ndarrays_to_parameters(self.initial_parameters)\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[Parameters, EvaluateRes]],\n",
    "        failures: List[BaseException],\n",
    "    ) -> Tuple[float, dict]:\n",
    "        if not results:\n",
    "            print(f\"‚ö†Ô∏è Round {rnd}: No evaluation results received!\")\n",
    "            return 0.0, {\"accuracy\": 0.0}\n",
    "\n",
    "        accuracies = [r.metrics[\"accuracy\"] for _, r in results]\n",
    "        global_accuracy = sum(accuracies) / len(accuracies)\n",
    "        print(f\"üìä Round {rnd}: Global Model Accuracy: {global_accuracy:.4f}\")\n",
    "        return 0.0, {\"accuracy\": global_accuracy}\n",
    "\n",
    "\n",
    "# ‚úÖ Initialize Strategy with Global Model Parameters\n",
    "strategy = CustomFedProx(initial_parameters=global_parameters)\n",
    "\n",
    "# ‚úÖ Start Federated Learning Server (with Secure Aggregation enabled)\n",
    "fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8080\",\n",
    "    strategy=strategy,\n",
    "    config=fl.server.ServerConfig(num_rounds=10)\n",
    ")\n",
    "\n",
    "# ‚úÖ Evaluate the Final Global Model\n",
    "global_model.eval()\n",
    "print(\"üéØ Final Global Model Evaluation Completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
