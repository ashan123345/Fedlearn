{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message d3e83597-ab01-4660-91d7-8deb0567854a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.6487\n",
      "Epoch 2/25, Loss: 0.5756\n",
      "Epoch 3/25, Loss: 0.5610\n",
      "Epoch 4/25, Loss: 0.5471\n",
      "Epoch 5/25, Loss: 0.5303\n",
      "Epoch 6/25, Loss: 0.5273\n",
      "Epoch 7/25, Loss: 0.5082\n",
      "Epoch 8/25, Loss: 0.5070\n",
      "Epoch 9/25, Loss: 0.4872\n",
      "Epoch 10/25, Loss: 0.4701\n",
      "Epoch 11/25, Loss: 0.4800\n",
      "Epoch 12/25, Loss: 0.4593\n",
      "Epoch 13/25, Loss: 0.4428\n",
      "Epoch 14/25, Loss: 0.4305\n",
      "Epoch 15/25, Loss: 0.4264\n",
      "Epoch 16/25, Loss: 0.4069\n",
      "Epoch 17/25, Loss: 0.3895\n",
      "Epoch 18/25, Loss: 0.3902\n",
      "Epoch 19/25, Loss: 0.3695\n",
      "Epoch 20/25, Loss: 0.3594\n",
      "Epoch 21/25, Loss: 0.3611\n",
      "Epoch 22/25, Loss: 0.3566\n",
      "Epoch 23/25, Loss: 0.3427\n",
      "Epoch 24/25, Loss: 0.3429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 44886422-f64a-4bae-a636-c78526569eca\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 268d7c86-0bd6-4c6a-b4b8-8f2338d2a575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 0.3395\n",
      "Client training complete. Sending updates.\n",
      "✅ Evaluation: Loss=0.5445, Accuracy=0.7125\n",
      "Epoch 1/25, Loss: 0.5143\n",
      "Epoch 2/25, Loss: 0.5214\n",
      "Epoch 3/25, Loss: 0.5215\n",
      "Epoch 4/25, Loss: 0.4958\n",
      "Epoch 5/25, Loss: 0.4871\n",
      "Epoch 6/25, Loss: 0.4764\n",
      "Epoch 7/25, Loss: 0.4711\n",
      "Epoch 8/25, Loss: 0.4487\n",
      "Epoch 9/25, Loss: 0.4449\n",
      "Epoch 10/25, Loss: 0.4395\n",
      "Epoch 11/25, Loss: 0.4393\n",
      "Epoch 12/25, Loss: 0.4449\n",
      "Epoch 13/25, Loss: 0.4366\n",
      "Epoch 14/25, Loss: 0.4296\n",
      "Epoch 15/25, Loss: 0.4130\n",
      "Epoch 16/25, Loss: 0.4236\n",
      "Epoch 17/25, Loss: 0.4228\n",
      "Epoch 18/25, Loss: 0.4118\n",
      "Epoch 19/25, Loss: 0.4184\n",
      "Epoch 20/25, Loss: 0.3968\n",
      "Epoch 21/25, Loss: 0.3964\n",
      "Epoch 22/25, Loss: 0.4073\n",
      "Epoch 23/25, Loss: 0.3841\n",
      "Epoch 24/25, Loss: 0.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 2a390746-72e5-4767-93dc-ef80bba48a2c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 0.3851\n",
      "Client training complete. Sending updates.\n",
      "✅ Evaluation: Loss=0.4896, Accuracy=0.7729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message d6efe5dd-5489-4fd8-a707-57dd3f9dba84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.4622\n",
      "Epoch 2/25, Loss: 0.4130\n",
      "Epoch 3/25, Loss: 0.4046\n",
      "Epoch 4/25, Loss: 0.3829\n",
      "Epoch 5/25, Loss: 0.3929\n",
      "Epoch 6/25, Loss: 0.4085\n",
      "Epoch 7/25, Loss: 0.3490\n",
      "Epoch 8/25, Loss: 0.3159\n",
      "Epoch 9/25, Loss: 0.3411\n",
      "Epoch 10/25, Loss: 0.3266\n",
      "Epoch 11/25, Loss: 0.3161\n",
      "Epoch 12/25, Loss: 0.2855\n",
      "Epoch 13/25, Loss: 0.2592\n",
      "Epoch 14/25, Loss: 0.2535\n",
      "Epoch 15/25, Loss: 0.2237\n",
      "Epoch 16/25, Loss: 0.2329\n",
      "Epoch 17/25, Loss: 0.2415\n",
      "Epoch 18/25, Loss: 0.2330\n",
      "Epoch 19/25, Loss: 0.2187\n",
      "Epoch 20/25, Loss: 0.1874\n",
      "Epoch 21/25, Loss: 0.1975\n",
      "Epoch 22/25, Loss: 0.2007\n",
      "Epoch 23/25, Loss: 0.1681\n",
      "Epoch 24/25, Loss: 0.1707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 0.1734\n",
      "Client training complete. Sending updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message d14b9087-912f-4dd8-ae7d-a93dd6209fb9\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 5f71a349-a2cd-4b39-8c10-c72ea2a86bd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation: Loss=0.6393, Accuracy=0.7896\n",
      "Epoch 1/25, Loss: 0.4307\n",
      "Epoch 2/25, Loss: 0.4231\n",
      "Epoch 3/25, Loss: 0.3837\n",
      "Epoch 4/25, Loss: 0.3836\n",
      "Epoch 5/25, Loss: 0.3168\n",
      "Epoch 6/25, Loss: 0.3329\n",
      "Epoch 7/25, Loss: 0.2995\n",
      "Epoch 8/25, Loss: 0.3031\n",
      "Epoch 9/25, Loss: 0.2520\n",
      "Epoch 10/25, Loss: 0.2579\n",
      "Epoch 11/25, Loss: 0.2633\n",
      "Epoch 12/25, Loss: 0.2565\n",
      "Epoch 13/25, Loss: 0.2576\n",
      "Epoch 14/25, Loss: 0.2332\n",
      "Epoch 15/25, Loss: 0.2848\n",
      "Epoch 16/25, Loss: 0.2646\n",
      "Epoch 17/25, Loss: 0.2423\n",
      "Epoch 18/25, Loss: 0.2556\n",
      "Epoch 19/25, Loss: 0.2816\n",
      "Epoch 20/25, Loss: 0.2666\n",
      "Epoch 21/25, Loss: 0.2585\n",
      "Epoch 22/25, Loss: 0.2684\n",
      "Epoch 23/25, Loss: 0.2710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Loss: 0.2843\n",
      "Epoch 25/25, Loss: 0.2715\n",
      "Client training complete. Sending updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 9320dd39-9299-49aa-a488-392619f0c623\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message dff92743-1780-4682-b912-69871737fcfd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation: Loss=0.5386, Accuracy=0.7958\n",
      "Epoch 1/25, Loss: 0.3749\n",
      "Epoch 2/25, Loss: 0.3090\n",
      "Epoch 3/25, Loss: 0.2902\n",
      "Epoch 4/25, Loss: 0.2710\n",
      "Epoch 5/25, Loss: 0.2565\n",
      "Epoch 6/25, Loss: 0.2525\n",
      "Epoch 7/25, Loss: 0.2285\n",
      "Epoch 8/25, Loss: 0.2174\n",
      "Epoch 9/25, Loss: 0.2483\n",
      "Epoch 10/25, Loss: 0.2109\n",
      "Epoch 11/25, Loss: 0.2061\n",
      "Epoch 12/25, Loss: 0.1708\n",
      "Epoch 13/25, Loss: 0.1484\n",
      "Epoch 14/25, Loss: 0.1554\n",
      "Epoch 15/25, Loss: 0.1506\n",
      "Epoch 16/25, Loss: 0.1428\n",
      "Epoch 17/25, Loss: 0.1333\n",
      "Epoch 18/25, Loss: 0.1302\n",
      "Epoch 19/25, Loss: 0.1183\n",
      "Epoch 20/25, Loss: 0.1232\n",
      "Epoch 21/25, Loss: 0.1124\n",
      "Epoch 22/25, Loss: 0.0924\n",
      "Epoch 23/25, Loss: 0.0934\n",
      "Epoch 24/25, Loss: 0.1039\n",
      "Epoch 25/25, Loss: 0.0923\n",
      "Client training complete. Sending updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 6c8aa7ed-0aa3-44c3-856d-1024a452de51\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 89c5ef44-749e-480e-9a27-fcc4614f6116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation: Loss=0.6617, Accuracy=0.8042\n",
      "Epoch 1/25, Loss: 0.3506\n",
      "Epoch 2/25, Loss: 0.3153\n",
      "Epoch 3/25, Loss: 0.3187\n",
      "Epoch 4/25, Loss: 0.2992\n",
      "Epoch 5/25, Loss: 0.2703\n",
      "Epoch 6/25, Loss: 0.2445\n",
      "Epoch 7/25, Loss: 0.2028\n",
      "Epoch 8/25, Loss: 0.1856\n",
      "Epoch 9/25, Loss: 0.1705\n",
      "Epoch 10/25, Loss: 0.1823\n",
      "Epoch 11/25, Loss: 0.1938\n",
      "Epoch 12/25, Loss: 0.1667\n",
      "Epoch 13/25, Loss: 0.1742\n",
      "Epoch 14/25, Loss: 0.1852\n",
      "Epoch 15/25, Loss: 0.1866\n",
      "Epoch 16/25, Loss: 0.1793\n",
      "Epoch 17/25, Loss: 0.1919\n",
      "Epoch 18/25, Loss: 0.2405\n",
      "Epoch 19/25, Loss: 0.1898\n",
      "Epoch 20/25, Loss: 0.2018\n",
      "Epoch 21/25, Loss: 0.1767\n",
      "Epoch 22/25, Loss: 0.1905\n",
      "Epoch 23/25, Loss: 0.1906\n",
      "Epoch 24/25, Loss: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 0.2137\n",
      "Client training complete. Sending updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 0d1a9db7-a036-49cf-8829-75f215763767\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 5fa95578-4ddf-4b77-b685-2d72d5f3e63d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation: Loss=0.5142, Accuracy=0.8229\n",
      "Epoch 1/25, Loss: 0.3155\n",
      "Epoch 2/25, Loss: 0.2273\n",
      "Epoch 3/25, Loss: 0.2526\n",
      "Epoch 4/25, Loss: 0.2137\n",
      "Epoch 5/25, Loss: 0.1937\n",
      "Epoch 6/25, Loss: 0.1937\n",
      "Epoch 7/25, Loss: 0.1836\n",
      "Epoch 8/25, Loss: 0.1529\n",
      "Epoch 9/25, Loss: 0.1492\n",
      "Epoch 10/25, Loss: 0.1628\n",
      "Epoch 11/25, Loss: 0.1610\n",
      "Epoch 12/25, Loss: 0.1443\n",
      "Epoch 13/25, Loss: 0.1361\n",
      "Epoch 14/25, Loss: 0.1210\n",
      "Epoch 15/25, Loss: 0.1044\n",
      "Epoch 16/25, Loss: 0.1052\n",
      "Epoch 17/25, Loss: 0.1018\n",
      "Epoch 18/25, Loss: 0.1096\n",
      "Epoch 19/25, Loss: 0.0943\n",
      "Epoch 20/25, Loss: 0.0982\n",
      "Epoch 21/25, Loss: 0.0778\n",
      "Epoch 22/25, Loss: 0.0840\n",
      "Epoch 23/25, Loss: 0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Loss: 0.0796\n",
      "Epoch 25/25, Loss: 0.0675\n",
      "Client training complete. Sending updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 9de07540-7a2b-48d4-ba9e-ada2e2f72c61\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message a6e726b8-bf83-4ee9-8fbd-e51df5df8765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation: Loss=0.6840, Accuracy=0.8042\n",
      "Epoch 1/25, Loss: 0.2801\n",
      "Epoch 2/25, Loss: 0.2923\n",
      "Epoch 3/25, Loss: 0.2433\n",
      "Epoch 4/25, Loss: 0.2018\n",
      "Epoch 5/25, Loss: 0.2338\n",
      "Epoch 6/25, Loss: 0.1932\n",
      "Epoch 7/25, Loss: 0.1634\n",
      "Epoch 8/25, Loss: 0.1764\n",
      "Epoch 9/25, Loss: 0.1488\n",
      "Epoch 10/25, Loss: 0.1358\n",
      "Epoch 11/25, Loss: 0.1246\n",
      "Epoch 12/25, Loss: 0.1303\n",
      "Epoch 13/25, Loss: 0.1339\n",
      "Epoch 14/25, Loss: 0.1378\n",
      "Epoch 15/25, Loss: 0.1613\n",
      "Epoch 16/25, Loss: 0.1651\n",
      "Epoch 17/25, Loss: 0.1376\n",
      "Epoch 18/25, Loss: 0.1398\n",
      "Epoch 19/25, Loss: 0.1513\n",
      "Epoch 20/25, Loss: 0.1660\n",
      "Epoch 21/25, Loss: 0.1662\n",
      "Epoch 22/25, Loss: 0.2018\n",
      "Epoch 23/25, Loss: 0.1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Loss: 0.1360\n",
      "Epoch 25/25, Loss: 0.1616\n",
      "Client training complete. Sending updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 58308670-e2d0-441a-9de7-b71b7dbd8c9e\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 4e627046-eaa2-4d6d-966a-2a73a1fcdbd4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation: Loss=0.5689, Accuracy=0.7979\n",
      "Epoch 1/25, Loss: 0.2507\n",
      "Epoch 2/25, Loss: 0.2249\n",
      "Epoch 3/25, Loss: 0.1847\n",
      "Epoch 4/25, Loss: 0.1638\n",
      "Epoch 5/25, Loss: 0.1839\n",
      "Epoch 6/25, Loss: 0.1541\n",
      "Epoch 7/25, Loss: 0.1856\n",
      "Epoch 8/25, Loss: 0.1531\n",
      "Epoch 9/25, Loss: 0.1394\n",
      "Epoch 10/25, Loss: 0.1403\n",
      "Epoch 11/25, Loss: 0.1260\n",
      "Epoch 12/25, Loss: 0.1367\n",
      "Epoch 13/25, Loss: 0.1197\n",
      "Epoch 14/25, Loss: 0.1016\n",
      "Epoch 15/25, Loss: 0.0959\n",
      "Epoch 16/25, Loss: 0.0918\n",
      "Epoch 17/25, Loss: 0.0634\n",
      "Epoch 18/25, Loss: 0.0638\n",
      "Epoch 19/25, Loss: 0.0578\n",
      "Epoch 20/25, Loss: 0.0675\n",
      "Epoch 21/25, Loss: 0.0760\n",
      "Epoch 22/25, Loss: 0.0697\n",
      "Epoch 23/25, Loss: 0.0709\n",
      "Epoch 24/25, Loss: 0.0688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 0.0651\n",
      "Client training complete. Sending updates.\n"
     ]
    },
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Cancelling all calls\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:8081 {created_time:\"2025-03-17T04:53:27.0617665+00:00\", grpc_status:14, grpc_message:\"Cancelling all calls\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 148\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader)), \u001b[38;5;28mlen\u001b[39m(test_loader\u001b[38;5;241m.\u001b[39mdataset), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy}\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# ✅ Start the Federated Learning Client\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m127.0.0.1:8081\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use .to_client() to avoid deprecation warning\u001b[39;49;00m\n\u001b[0;32m    151\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Rreserch work\\fedenvioremnt\\.venv\\lib\\site-packages\\flwr\\client\\app.py:201\u001b[0m, in \u001b[0;36mstart_client\u001b[1;34m(server_address, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time)\u001b[0m\n\u001b[0;32m    198\u001b[0m warn_deprecated_feature(name\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[0;32m    200\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_ENTER)\n\u001b[1;32m--> 201\u001b[0m \u001b[43mstart_client_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_client_app_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauthentication_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauthentication_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_LEAVE)\n",
      "File \u001b[1;32md:\\Rreserch work\\fedenvioremnt\\.venv\\lib\\site-packages\\flwr\\client\\app.py:438\u001b[0m, in \u001b[0;36mstart_client_internal\u001b[1;34m(server_address, node_config, load_client_app_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time, flwr_path, isolation, clientappio_api_address)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;66;03m# Receive\u001b[39;00m\n\u001b[1;32m--> 438\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Wait for 3s before asking again\u001b[39;00m\n",
      "File \u001b[1;32md:\\Rreserch work\\fedenvioremnt\\.venv\\lib\\site-packages\\flwr\\client\\grpc_client\\connection.py:140\u001b[0m, in \u001b[0;36mgrpc_connection.<locals>.receive\u001b[1;34m()\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreceive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Message:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Receive ServerMessage proto\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_message_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# ServerMessage proto --> *Ins --> RecordSet\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     field \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mWhichOneof(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Rreserch work\\fedenvioremnt\\.venv\\lib\\site-packages\\grpc\\_channel.py:543\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Rreserch work\\fedenvioremnt\\.venv\\lib\\site-packages\\grpc\\_channel.py:969\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Cancelling all calls\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:8081 {created_time:\"2025-03-17T04:53:27.0617665+00:00\", grpc_status:14, grpc_message:\"Cancelling all calls\"}\"\n>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# ✅ Set device for computation (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ Load dataset\n",
    "file_path = \"client_3.csv\"  # Adjust path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ✅ Ensure target column exists\n",
    "target_column = \"TenYearCHD\"\n",
    "if target_column not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "# ✅ Separate Features and Target\n",
    "X = df.drop(columns=[target_column]).values\n",
    "y = df[target_column].values\n",
    "\n",
    "# ✅ Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# ✅ Train/Test Split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ✅ Convert to PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# ✅ Create Custom Dataset & DataLoaders\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def create_dataloaders(batch_size=64):\n",
    "    train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = create_dataloaders()\n",
    "\n",
    "# ✅ Define MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, dropout=0.2587):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.GELU()\n",
    "        ]\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "        layers.append(nn.Linear(hidden_dim, 2))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ✅ Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = MLP(input_dim=input_dim).to(device)\n",
    "\n",
    "# ✅ Define optimizer, loss function, and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00507)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)  # T_max matches epochs\n",
    "\n",
    "# ✅ Fix Parameter Handling\n",
    "def get_parameters(model: nn.Module) -> List[np.ndarray]:\n",
    "    return [val.cpu().detach().numpy() for val in model.state_dict().values()]\n",
    "\n",
    "def set_parameters(model: nn.Module, parameters: List[np.ndarray]) -> None:\n",
    "    state_dict = model.state_dict()\n",
    "    new_state_dict = {k: torch.tensor(v).to(device) for k, v in zip(state_dict.keys(), parameters)}\n",
    "    model.load_state_dict(new_state_dict, strict=True)\n",
    "\n",
    "# ✅ Define the Federated Learning Client\n",
    "class FLClient(fl.client.NumPyClient):\n",
    "    def get_parameters(self, config: Dict[str, str]) -> List[np.ndarray]:\n",
    "        return get_parameters(model)\n",
    "\n",
    "    def set_parameters(self, parameters: List[np.ndarray]) -> None:\n",
    "        set_parameters(model, parameters)\n",
    "\n",
    "    def fit(self, parameters: List[np.ndarray], config: Dict[str, str]) -> Tuple[List[np.ndarray], int, Dict]:\n",
    "        self.set_parameters(parameters)\n",
    "        model.train()\n",
    "        for epoch in range(25):  # Train for 25 local epochs\n",
    "            total_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            scheduler.step()\n",
    "            print(f\"Epoch {epoch+1}/25, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        print(\"Client training complete. Sending updates.\")\n",
    "        return self.get_parameters(config), len(train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters: List[np.ndarray], config: Dict[str, str]) -> Tuple[float, int, Dict]:\n",
    "        self.set_parameters(parameters)\n",
    "        model.eval()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "        accuracy = correct / total if total > 0 else 0.0\n",
    "        print(f\"✅ Evaluation: Loss={total_loss/len(test_loader):.4f}, Accuracy={accuracy:.4f}\")\n",
    "        return float(total_loss / len(test_loader)), len(test_loader.dataset), {\"accuracy\": accuracy}\n",
    "\n",
    "# ✅ Start the Federated Learning Client\n",
    "fl.client.start_client(\n",
    "    server_address=\"127.0.0.1:8081\",\n",
    "    client=FLClient().to_client(),  # Use .to_client() to avoid deprecation warning\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
