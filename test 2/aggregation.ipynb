{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
      "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
      "\n",
      "\t\t$ flower-superlink --insecure\n",
      "\n",
      "\tTo view usage and all available options, run:\n",
      "\n",
      "\t\t$ flower-superlink --help\n",
      "\n",
      "\tUsing `start_server()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "Exception in thread Thread-9 (wait_for_clients):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ashan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=5, no round_timeout\n",
      "    self.run()\n",
      "  File \"d:\\Rreserch work\\fedenvioremnt\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\Ashan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Ashan\\AppData\\Local\\Temp\\ipykernel_4080\\793007757.py\", line 46, in wait_for_clients\n",
      "TypeError: 'module' object is not callable\n",
      "\u001b[92mINFO \u001b[0m:      Flower ECE: gRPC server running (5 rounds), SSL is disabled\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Waiting for 2 clients to connect...ğŸš€ Starting Flower server on port 8081...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import time\n",
    "import threading\n",
    "\n",
    "REQUIRED_CLIENTS = 2  # Change based on your setup\n",
    "\n",
    "class CustomFedAvg(fl.server.strategy.FedAvg):\n",
    "    \"\"\"Federated Averaging with controlled shutdown and robust aggregation.\"\"\"\n",
    "\n",
    "    def __init__(self, num_rounds=5):\n",
    "        super().__init__()\n",
    "        self.num_rounds = num_rounds\n",
    "\n",
    "    def aggregate_fit(self, rnd, results, failures):\n",
    "        \"\"\"Aggregates model updates from clients.\"\"\"\n",
    "        print(f\"âœ… Round {rnd}: {len(results)} client updates, {len(failures)} failures.\")\n",
    "        return super().aggregate_fit(rnd, results, failures)\n",
    "\n",
    "    def aggregate_evaluate(self, rnd, results, failures):\n",
    "        \"\"\"Aggregate evaluation results while handling missing client responses.\"\"\"\n",
    "        valid_results = [(res[0], res[1]) for res in results if isinstance(res, tuple) and len(res) == 2]\n",
    "\n",
    "        if valid_results:\n",
    "            aggregated_loss = sum(res[0] for res in valid_results) / len(valid_results)\n",
    "            aggregated_metrics = {\n",
    "                key: sum(d[key] for _, d in valid_results) / len(valid_results)\n",
    "                for key in valid_results[0][1]\n",
    "            }\n",
    "\n",
    "            print(f\"ğŸ“Š Round {rnd} Evaluation: Loss={aggregated_loss:.4f}, Metrics={aggregated_metrics}\")\n",
    "\n",
    "            if rnd == self.num_rounds:\n",
    "                print(\"ğŸ† Training complete. Server shutting down.\")\n",
    "                time.sleep(2)\n",
    "                exit(0)\n",
    "\n",
    "            return aggregated_loss, aggregated_metrics\n",
    "\n",
    "        print(f\"âš ï¸ No valid evaluation results in round {rnd}. Returning default values.\")\n",
    "        return 0.0, {}  \n",
    "\n",
    "def wait_for_clients():\n",
    "    \"\"\"Ensures all required clients connect before training starts.\"\"\"\n",
    "    print(f\"ğŸ”„ Waiting for {REQUIRED_CLIENTS} clients to connect...\")\n",
    "\n",
    "    while len(fl.server.client_manager().all()) < REQUIRED_CLIENTS:\n",
    "        time.sleep(1)  \n",
    "\n",
    "    print(\"ğŸš€ All clients connected. Starting federated learning.\")\n",
    "\n",
    "def start_server():\n",
    "    \"\"\"Start the Flower server with a client wait mechanism.\"\"\"\n",
    "    num_rounds = 5\n",
    "    strategy = CustomFedAvg(num_rounds)\n",
    "\n",
    "    threading.Thread(target=wait_for_clients, daemon=True).start()\n",
    "\n",
    "    print(\"ğŸš€ Starting Flower server on port 8081...\")\n",
    "\n",
    "    fl.server.start_server(\n",
    "        server_address=\"0.0.0.0:8081\",  \n",
    "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
    "        strategy=strategy,\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_server()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "server for testing a clinet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'flwr.server' has no attribute 'ClientFitResult'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Custom Federated Averaging Strategy\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mFedAvgCustom\u001b[39;00m(fl\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mFedAvg):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_rounds: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m, in \u001b[0;36mFedAvgCustom\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnected_clients \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maggregate_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, rnd: \u001b[38;5;28mint\u001b[39m, results: List[\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClientFitResult\u001b[49m], failures: List[\u001b[38;5;167;01mException\u001b[39;00m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[np\u001b[38;5;241m.\u001b[39mndarray], Dict]:\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates model updates from clients and sends them to the global server.\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     aggregated_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39maggregate_fit(rnd, results, failures)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'flwr.server' has no attribute 'ClientFitResult'"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from flwr.common import parameters_to_ndarrays, ndarrays_to_parameters\n",
    "\n",
    "# Define the MLP model (same as the one used by the clients)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, dropout=0.2587):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.GELU()\n",
    "        ]\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "        layers.append(nn.Linear(hidden_dim, 2))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Custom Federated Averaging Strategy\n",
    "class FedAvgCustom(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, num_rounds: int):\n",
    "        super().__init__()\n",
    "        self.num_rounds = num_rounds\n",
    "        self.current_round = 0\n",
    "        self.connected_clients = 0\n",
    "\n",
    "    def aggregate_fit(self, rnd: int, results: List[fl.server.ClientFitResult], failures: List[Exception]) -> Tuple[List[np.ndarray], Dict]:\n",
    "        \"\"\"Aggregates model updates from clients and sends them to the global server.\"\"\"\n",
    "        aggregated_parameters = super().aggregate_fit(rnd, results, failures)\n",
    "\n",
    "        if aggregated_parameters:\n",
    "            print(f\"âœ… Round {rnd} aggregated successfully!\")\n",
    "            self.current_round = rnd\n",
    "\n",
    "            # Validate and send to global server\n",
    "            if validate_aggregated_parameters(aggregated_parameters[0]):\n",
    "                send_to_global_server(aggregated_parameters[0], self.current_round == self.num_rounds)\n",
    "            else:\n",
    "                print(\"âŒ Aggregated parameters failed validation! Not sending to the global server.\")\n",
    "\n",
    "        return aggregated_parameters\n",
    "\n",
    "\n",
    "# Validate aggregated model parameters\n",
    "def validate_aggregated_parameters(parameters):\n",
    "    \"\"\"Validate aggregated model parameters before sending them to the global server.\"\"\"\n",
    "    try:\n",
    "        ndarrays = parameters_to_ndarrays(parameters)\n",
    "        if len(ndarrays) == 10:  # Expecting 10 layers (512-512-256-128 MLP)\n",
    "            print(\"âœ… Aggregated parameters validated successfully!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âŒ Invalid parameter count! Expected 10, got {len(ndarrays)}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Parameter validation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Wait for the global server connection\n",
    "def wait_for_global_server(host=\"127.0.0.1\", port=9090):\n",
    "    \"\"\"Wait for the global server to connect before starting FL.\"\"\"\n",
    "    print(\"ğŸ”„ Waiting for the global server to connect...\")\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n",
    "        server_socket.bind((host, port))\n",
    "        server_socket.listen(1)\n",
    "\n",
    "        conn, addr = server_socket.accept()\n",
    "        with conn:\n",
    "            print(f\"âœ… Global server connected from {addr}. Ready to receive model updates.\")\n",
    "\n",
    "\n",
    "# Send aggregated updates to the global server\n",
    "def send_to_global_server(aggregated_parameters, is_last_round, host=\"127.0.0.1\", port=9091):\n",
    "    \"\"\"Send aggregated model updates to the global server, with a termination signal if last round.\"\"\"\n",
    "    print(\"ğŸ“¤ Sending aggregated updates to the global server...\")\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "        try:\n",
    "            sock.connect((host, port))\n",
    "\n",
    "            if is_last_round:\n",
    "                sock.sendall(\"STOP\".encode())  \n",
    "                print(\"ğŸ›‘ Sent termination signal to global server!\")\n",
    "            else:\n",
    "                # Convert Parameters to ndarrays\n",
    "                ndarrays = parameters_to_ndarrays(aggregated_parameters)\n",
    "\n",
    "                # PyTorch model parameters for fine-tuned architecture\n",
    "                parameter_names = [\n",
    "                    \"fc1.weight\", \"fc1.bias\", \n",
    "                    \"fc2.weight\", \"fc2.bias\", \n",
    "                    \"fc3.weight\", \"fc3.bias\", \n",
    "                    \"fc4.weight\", \"fc4.bias\",\n",
    "                    \"fc5.weight\", \"fc5.bias\"\n",
    "                ]\n",
    "                \n",
    "                parameters_dict = {name: param.tolist() for name, param in zip(parameter_names, ndarrays)}\n",
    "\n",
    "                # Serialize and send\n",
    "                serialized_parameters = pickle.dumps(parameters_dict)\n",
    "                sock.sendall(serialized_parameters)\n",
    "                print(\"âœ… Aggregated updates sent to the global server!\")\n",
    "        except ConnectionRefusedError:\n",
    "            print(\"âŒ Could not connect to the global server.\")\n",
    "\n",
    "\n",
    "# Wait for at least `min_clients` clients to connect\n",
    "def wait_for_clients(host=\"0.0.0.0\", port=8081, min_clients=2):\n",
    "    \"\"\"Wait for at least `min_clients` clients to connect before starting federated learning.\"\"\"\n",
    "    print(f\"ğŸ”„ Waiting for at least {min_clients} clients to connect...\")\n",
    "\n",
    "    connected_clients = 0\n",
    "    client_sockets = []\n",
    "\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n",
    "        server_socket.bind((host, port))\n",
    "        server_socket.listen(5)\n",
    "\n",
    "        while connected_clients < min_clients:\n",
    "            conn, addr = server_socket.accept()\n",
    "            print(f\"âœ… Client {connected_clients+1}/{min_clients} connected from {addr}\")\n",
    "\n",
    "            try:\n",
    "                conn.settimeout(5)\n",
    "                conn.sendall(b\"PING\")\n",
    "                response = conn.recv(1024)\n",
    "                if response.strip() == b\"PONG\":\n",
    "                    client_sockets.append(conn)\n",
    "                    connected_clients += 1\n",
    "                else:\n",
    "                    print(\"âš ï¸ Client did not respond correctly. Removing connection.\")\n",
    "                    conn.close()\n",
    "            except socket.timeout:\n",
    "                print(\"âš ï¸ Client did not respond in time. Removing connection.\")\n",
    "                conn.close()\n",
    "\n",
    "    print(\"ğŸš€ Minimum client threshold reached! Waiting for final confirmation...\")\n",
    "    \n",
    "    # Ensure all clients are fully ready before starting training\n",
    "    for sock in client_sockets:\n",
    "        try:\n",
    "            sock.sendall(b\"READY\")\n",
    "            confirmation = sock.recv(1024)\n",
    "            if confirmation.strip() != b\"ACK\":\n",
    "                print(\"âš ï¸ Client did not confirm readiness. Removing connection.\")\n",
    "                client_sockets.remove(sock)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error verifying client readiness: {e}\")\n",
    "            client_sockets.remove(sock)\n",
    "\n",
    "    if len(client_sockets) < min_clients:\n",
    "        print(\"âŒ Not enough ready clients. Restarting client wait...\")\n",
    "        return wait_for_clients(host, port, min_clients)  # Retry if necessary\n",
    "\n",
    "    print(\"âœ… All clients confirmed readiness. Starting federated learning now!\")\n",
    "    return client_sockets\n",
    "\n",
    "\n",
    "def start_server():\n",
    "    # Waiting for global server connection\n",
    "    wait_for_global_server()  \n",
    "    \n",
    "    # Wait for clients to connect\n",
    "    print(\"âœ… Global server connected. Now waiting for clients...\")\n",
    "    client_sockets = wait_for_clients()  # Get connected clients\n",
    "\n",
    "    print(\"ğŸ”„ Verifying active client connections before starting training...\")\n",
    "    \n",
    "    for sock in client_sockets:\n",
    "        try:\n",
    "            sock.sendall(b\"PING\")\n",
    "            response = sock.recv(1024)\n",
    "            if response != b\"PONG\":\n",
    "                print(\"âš ï¸ Client did not respond correctly. Removing connection.\")\n",
    "                client_sockets.remove(sock)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error communicating with client: {e}\")\n",
    "            client_sockets.remove(sock)\n",
    "\n",
    "    if len(client_sockets) < 2:\n",
    "        print(\"âŒ Not enough active clients. Restarting client wait...\")\n",
    "        client_sockets = wait_for_clients()  # Wait again if necessary\n",
    "\n",
    "    print(\"âœ… All clients verified. Starting federated learning now!\")\n",
    "\n",
    "    # Define and configure strategy for federated learning\n",
    "    num_rounds = 5  \n",
    "    strategy = FedAvgCustom(num_rounds)\n",
    "\n",
    "    fl.server.start_server(\n",
    "        server_address=\"0.0.0.0:8081\",\n",
    "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
    "        strategy=strategy,\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_server()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my saved text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
      "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
      "\n",
      "\t\t$ flower-superlink --insecure\n",
      "\n",
      "\tTo view usage and all available options, run:\n",
      "\n",
      "\t\t$ flower-superlink --help\n",
      "\n",
      "\tUsing `start_server()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      Flower ECE: gRPC server running (5 rounds), SSL is disabled\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model updated at round 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model updated at round 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model updated at round 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model updated at round 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 37.97s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.663948267698288\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6997112929821014\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.754900723695755\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.8217424154281616\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.8074790835380554\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model updated at round 5.\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "# Define a simple neural network (same as the client)\n",
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(15, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the global model\n",
    "global_model = SimpleNN()\n",
    "\n",
    "# Helper function to set model parameters\n",
    "def set_parameters(model, parameters):\n",
    "    for param, new_param in zip(model.parameters(), parameters):\n",
    "        param.data = torch.tensor(new_param)\n",
    "\n",
    "# Custom Federated Strategy\n",
    "class CustomFedAvg(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "        aggregated_parameters = super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            set_parameters(global_model, fl.common.parameters_to_ndarrays(aggregated_parameters[0]))\n",
    "\n",
    "        print(f\"Global model updated at round {server_round}.\")\n",
    "        return aggregated_parameters\n",
    "\n",
    "# Start the server\n",
    "def start_server():\n",
    "    strategy = CustomFedAvg(\n",
    "        fraction_fit=1.0,         # Require all available clients to participate\n",
    "        min_fit_clients=2,        # Ensure at least 2 clients train in each round\n",
    "        min_available_clients=2,  # Ensure at least 2 clients are available before training starts\n",
    "    )\n",
    "\n",
    "    fl.server.start_server(\n",
    "        server_address=\"127.0.0.1:8081\",\n",
    "        config=fl.server.ServerConfig(num_rounds=5),\n",
    "        strategy=strategy,\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_server()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
